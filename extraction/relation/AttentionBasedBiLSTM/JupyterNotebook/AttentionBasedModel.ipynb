{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies & files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing required packages - Please uncomment code to install dependencies\n",
    "# !pip install tensorflow\n",
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttentionBasedModel import AttentionBasedBiLstmModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset from Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file\n",
      "[['Although this effect was noted even when cholestyramine was given 4 hours prior to fluvastatin, this regimen did not result in diminished efficacy.', 'cholestyramine', 'drug', '41', '54', 'fluvastatin', 'drug', '83', '93', 'effect'], ['The system as described above has its greatest application in an arrayed configuration of antenna elements.', 'configuration', 'Null', '73', '85', 'elements', 'Null', '98', '106', 'Component-Whole(e2,e1)'], ['Bill Gates is the founder of Microsoft.', 'Bill Gates', 'Person', '0', '9', 'Microsoft', 'organiztion', '29', '37', 'founder']]\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/relation_extraction_test_input.txt\"\n",
    "common_format_data = AttentionBasedBiLstmModel.read_dataset(input_file)\n",
    "print(common_format_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model with below paramters..................\n",
      "Max Sentence Length:-  90\n",
      "Dev Sample Percentage:=-  0.1\n",
      "Embedding Path:-  ../res/glove.6B.100d.txt\n",
      "Embedding Dimensions:-  100\n",
      "Dropout probability of embedding layer:-  0.7\n",
      "Dimensionality of RNN hidden:-  100\n",
      "Dropout probability of RNN:-  0.7\n",
      "L2 Regularization lamba:-  1e-5\n",
      "Batch Size:-  10\n",
      "Num Epochs:-  100\n",
      "Display Every:-  10\n",
      "Evaluate Every:-  100\n",
      "Number of Checkpoints:-  5\n",
      "Learning Rate:-  1.0\n",
      "Decay Rate:-  0.9\n",
      "\n",
      "\n",
      "Training Model..................\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ../src/train.py:29: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "Text Vocabulary Size: 50\n",
      "x = (3, 90)\n",
      "y = (3, 3)\n",
      "\n",
      "\n",
      "Train/Dev split: 2/1\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From ../src/att_lstm.py:24: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ../src/att_lstm.py:28: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From ../src/att_lstm.py:36: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From ../src/att_lstm.py:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "Writing to /Users/sonaligujarathi/Documents/Integration Web/Project/AttentionBasedBiLSTM/runs/models\n",
      "\n",
      "Loading glove file ../res/glove.6B.100d.txt\n",
      "Success to load pre-trained word2vec model!\n",
      "\n",
      "2019-04-30T21:29:06.750014: step 10, loss 0.265943, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:06.935868: step 10, loss 4.58239, acc 0\n",
      "Saved model checkpoint to /Users/sonaligujarathi/Documents/Integration Web/Project/AttentionBasedBiLSTM/runs/models/checkpoints/model-0-10\n",
      "\n",
      "2019-04-30T21:29:07.310825: step 20, loss 0.0353253, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:07.315998: step 20, loss 5.48212, acc 0\n",
      "2019-04-30T21:29:07.566519: step 30, loss 0.0186645, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:07.576877: step 30, loss 5.812, acc 0\n",
      "2019-04-30T21:29:07.980257: step 40, loss 0.0140726, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:07.983745: step 40, loss 6.32098, acc 0\n",
      "2019-04-30T21:29:08.295212: step 50, loss 0.0121178, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:08.300569: step 50, loss 6.28925, acc 0\n",
      "2019-04-30T21:29:08.514193: step 60, loss 0.0105653, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:08.519023: step 60, loss 6.47275, acc 0\n",
      "2019-04-30T21:29:08.769563: step 70, loss 0.0106811, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:08.773825: step 70, loss 6.83952, acc 0\n",
      "2019-04-30T21:29:09.050449: step 80, loss 0.0119362, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:09.062104: step 80, loss 7.21243, acc 0\n",
      "2019-04-30T21:29:09.286177: step 90, loss 0.0117347, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:09.290433: step 90, loss 7.83772, acc 0\n",
      "2019-04-30T21:29:09.592621: step 100, loss 0.0108512, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2019-04-30T21:29:09.606239: step 100, loss 7.83907, acc 0\n",
      "\n",
      "\n",
      "Training Completed.................\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Usage : .train(common_format_data,embedding_path =\"glove.6B.100d.txt\",)\n",
    "Compulsory parameter : embedding_path \n",
    "Optional parameters : such as number of epochs,learning rate etc can be given. \n",
    "dev_sample_percentage : Percentage of the training data to use for validation\n",
    "\n",
    "hidden_size : Dimensionality of RNN hidden\n",
    "rnn_dropout_keep_prob : Dropout keep probability of RNN\n",
    "\n",
    "batch_size:Batch Size\n",
    "num_epochs :Number of training epochs\n",
    "display_every :Number of iterations to display training information\n",
    "evaluate_every : Evaluate model on dev set after this many steps\n",
    "num_checkpoints: Number of checkpoints to store\n",
    "learning_rate : Which learning rate to start with\n",
    "\"\"\"\n",
    "AttentionBasedBiLstmModel.train(common_format_data,embedding_path =\"../res/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file\n",
      "Evaluating Model...............\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sonaligujarathi/Documents/Integration Web/Project/AttentionBasedBiLSTM/runs/models/checkpoints/model-0-10\n",
      " Precision: 0.50000000\t    Recall: 0.33333333\t    F1: 0.40000000\n",
      " Precision: 0.50000000\t    Recall: 0.33333333\t    F1: 0.40000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reading test file and sending data to evaluate with help of checkpoint_dir\n",
    "\"\"\"\n",
    "test_file = \"../data/relation_extraction_test_input.txt\"\n",
    "test_common_format_data = AttentionBasedBiLstmModel.read_dataset(test_file)\n",
    "AttentionBasedBiLstmModel.evaluate(test_common_format_data,checkpoint_dir = \"../runs/models/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file\n",
      "Loading model for predicting............\n",
      "INFO:tensorflow:Restoring parameters from /Users/sonaligujarathi/Documents/Integration Web/Project/AttentionBasedBiLSTM/runs/models/checkpoints/model-0-10\n",
      "\n",
      "\n",
      "\n",
      "Sentence :-  Although this effect was noted even when cholestyraminee was given 4 hours prior to fluvastatinn, this regimen did not result in diminished efficacy.\n",
      "Entity 1 :-  cholestyramine\n",
      "Entity 2 :-  fluvastatin\n",
      "Predicted Relation :-  effect\n",
      "Sentence :-  The system as described above has its greatest application in an arrayed configurationn of antenna elements.\n",
      "Entity 1 :-  configuration\n",
      "Entity 2 :-  elements\n",
      "Predicted Relation :-  effect\n",
      "Sentence :-  Bill Gatess is the founder of Microsoftt.\n",
      "Entity 1 :-  Bill Gates\n",
      "Entity 2 :-  Microsoft\n",
      "Predicted Relation :-  founder\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reading predict file in common format and evaluate with help of checkpoint_dir\n",
    "\"\"\"\n",
    "predict_file = \"../data/relation_extraction_test_input.txt\"\n",
    "predict_common_format_data = AttentionBasedBiLstmModel.read_dataset(test_file)\n",
    "predictions = AttentionBasedBiLstmModel.predict(predict_common_format_data,checkpoint_dir = \"../runs/models/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ../saved_model_dir\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save Model at given location\n",
    "\"\"\"\n",
    "file_save_model = \"../saved_model_dir\"\n",
    "AttentionBasedBiLstmModel.save_model(file_save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/sonaligujarathi/Documents/Integration Web/Project/AttentionBasedBiLSTM/runs/models/checkpoints/model-0-10\n",
      "<tensorflow.python.client.session.Session object at 0x12b2607b8>\n",
      "<tensorflow.contrib.learn.python.learn.preprocessing.text.VocabularyProcessor object at 0x105974b00>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x12b455da0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.framework.ops.Graph at 0x12b455da0>,\n",
       " <tensorflow.python.client.session.Session at 0x12b2607b8>,\n",
       " <tensorflow.contrib.learn.python.learn.preprocessing.text.VocabularyProcessor at 0x105974b00>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading Model from file\n",
    "\"\"\"\n",
    "AttentionBasedBiLstmModel.load_model(file_save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
