{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTL Demo\n",
    "\n",
    "### First, import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "from logging import info\n",
    "import sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, merge\n",
    "from keras.layers import Reshape, Convolution2D, Dropout\n",
    "\n",
    "import __main__\n",
    "__main__.__file__ = \"./\"\n",
    "from models.ltlib import filelog\n",
    "from models.ltlib import conlldata\n",
    "from models.ltlib import viterbi\n",
    "\n",
    "from models.ltlib.features import NormEmbeddingFeature, SennaCapsFeature\n",
    "from models.ltlib.features import windowed_inputs\n",
    "from models.ltlib.callbacks import token_evaluator, EpochTimer\n",
    "from models.ltlib.layers import concat, inputs_and_embeddings\n",
    "from models.ltlib.settings import cli_settings, log_settings\n",
    "from models.ltlib.optimizers import get_optimizer\n",
    "from models.ltlib.output import save_token_predictions\n",
    "\n",
    "from models.config import Defaults\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "\n",
    "sys.argv = [\"single_task.py\", \"./data/CHEMDNER\", \"./vectorfile/bio_nlp_vec/PubMed-shuffle-win-30.bin\"]\n",
    "\n",
    "default_stdout = sys.stdout\n",
    "default_stderr = sys.stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = default_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the class for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL:\n",
    "    def __init__(self):\n",
    "        self.config = cli_settings(['datadir', 'wordvecs'], Defaults)\n",
    "        \n",
    "    def convert_ground_truth(self, data, *args, **kwargs):  # <--- implemented PER class\n",
    "        pass\n",
    "\n",
    "    def read_dataset(self, file_dict, dataset_name):  # <--- implemented PER class\n",
    "        data = conlldata.load_dir(self.config.datadir, self.config)\n",
    "        return data\n",
    "            \n",
    "            \n",
    "    def train(self, data):  # <--- implemented PER class\n",
    "        if self.config.viterbi:\n",
    "            vmapper = viterbi.TokenPredictionMapper(data.train.sentences)\n",
    "        else:\n",
    "            vmapper = None\n",
    "\n",
    "        w2v = NormEmbeddingFeature.from_file(self.config.wordvecs,\n",
    "                                             max_rank=self.config.max_vocab_size,\n",
    "                                             vocabulary=data.vocabulary,\n",
    "                                             name='words')\n",
    "        features = [w2v]\n",
    "        if self.config.word_features:\n",
    "            features.append(SennaCapsFeature(name='caps'))\n",
    "\n",
    "        data.tokens.add_features(features)\n",
    "        data.tokens.add_inputs(windowed_inputs(self.config.window_size, features))\n",
    "\n",
    "        # Log word vector feature stat summary\n",
    "        #info('{}: {}'.format(self.config.wordvecs, w2v.summary()))\n",
    "\n",
    "        inputs, embeddings = inputs_and_embeddings(features, self.config)\n",
    "\n",
    "        seq = concat(embeddings)\n",
    "        cshape = (self.config.window_size, sum(f.output_dim for f in features))\n",
    "\n",
    "        seq_reshape = Reshape(cshape+(1,))(seq)\n",
    "\n",
    "\n",
    "        # Convolutions\n",
    "        conv_outputs = []\n",
    "        for filter_size, filter_num in zip(self.config.filter_sizes, self.config.filter_nums):\n",
    "            conv = Convolution2D(filter_num, filter_size, cshape[1],\n",
    "                                 activation='relu')(seq_reshape)\n",
    "            cout = Flatten()(conv)\n",
    "            conv_outputs.append(cout)\n",
    "        seq_covout = merge(conv_outputs, mode='concat', concat_axis=-1)\n",
    "\n",
    "\n",
    "        for size in self.config.hidden_sizes:\n",
    "            seq_2 = Dense(size, activation=self.config.hidden_activation)(seq_covout)\n",
    "        seq_3 = Dropout(self.config.output_drop_prob)(seq_2)\n",
    "        out = Dense(data.tokens.target_dim, activation='softmax')(seq_3)\n",
    "        self.model = Model(input=inputs, output=out)\n",
    "\n",
    "\n",
    "        optimizer = get_optimizer(self.config)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        callbacks = [\n",
    "            EpochTimer(),\n",
    "            #token_evaluator(data.train, mapper=vmapper, config=config),\n",
    "            #token_evaluator(data.test, mapper=vmapper, config=config),\n",
    "        ]\n",
    "\n",
    "        percnt_keep = self.config.percent_keep\n",
    "        amt_keep = len(data.train.tokens.inputs['words']) * percnt_keep\n",
    "        print(\"Total: %s. Keeping: %s\" % (len(data.train.tokens.inputs['words']), amt_keep))\n",
    "        start = random.randrange(int(len(data.train.tokens.inputs['words']) - amt_keep + 1))\n",
    "        end = int(start + amt_keep)\n",
    "        x = data.train.tokens.inputs['words'][start:end]\n",
    "\n",
    "\n",
    "        self.model.fit(\n",
    "            #data.train.tokens.inputs,\n",
    "            x,\n",
    "            data.train.tokens.targets[start:end],\n",
    "            callbacks=callbacks,\n",
    "            batch_size=self.config.batch_size,\n",
    "            nb_epoch=1,\n",
    "            verbose=1\n",
    "        )\n",
    "      \n",
    "    def predict(self, data, *args, **kwargs):  # <--- implemented PER class WITH requirement on OUTPUT format!\n",
    "        name = \"chemdner_output\"\n",
    "        save_token_predictions(name, data.test, self.model, conlldata.write)\n",
    "\n",
    "        return \"./prediction/\"+name+\".tsv\"\n",
    "\n",
    "    def evaluate(self, predictions, groundTruths, *args,\n",
    "                 **kwargs):  # <--- common ACROSS ALL classes. Requirement that INPUT format uses output from predict()!\n",
    "        f = open(predictions, \"r\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        ground = []\n",
    "        predict = []\n",
    "\n",
    "        for line in lines:\n",
    "            if len(line) < 2:\n",
    "                 continue\n",
    "            tmp = line.split(\" \")\n",
    "            ground.append(tmp[1])\n",
    "            predict.append(tmp[2].strip())\n",
    "\n",
    "        labels = list(set(predict))\n",
    "\n",
    "        eval = precision_recall_fscore_support(ground, predict, labels=labels)\n",
    "        test_score = eval[2]\n",
    "\n",
    "        for idx, label in enumerate(labels):\n",
    "            print(\"{} Precision:{:.2f}% Recall:{:.2f}% F1_score:{:.2f}% \".format(label, eval[0][idx]*100, eval[1][idx]*100, eval[2][idx]*100))\n",
    "\n",
    "        eval_summary = precision_recall_fscore_support(ground, predict, average='macro', labels=labels)\n",
    "        \n",
    "        return eval_summary\n",
    "\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial the MTL class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./:md5:4246eea35eedb1d89e578715e4764f5f/1a7b4c315b31a418d861cf5eb9b7fdc9\n",
      "{\n",
      "    \"batch_size\": 200,\n",
      "    \"datadir\": \"./data/CHEMDNER\",\n",
      "    \"encoding\": \"utf-8\",\n",
      "    \"epochs\": 20,\n",
      "    \"evaluate_every\": 5000,\n",
      "    \"evaluate_min\": 0,\n",
      "    \"filter_nums\": [ 100, 100, 100 ],\n",
      "    \"filter_sizes\": [ 3, 4, 5 ],\n",
      "    \"fixed_wordvecs\": true,\n",
      "    \"hidden_activation\": \"relu\",\n",
      "    \"hidden_sizes\": [ 1200 ],\n",
      "    \"iobes\": false,\n",
      "    \"learning_rate\": 0.0001,\n",
      "    \"max_tokens\": null,\n",
      "    \"max_vocab_size\": 1000000,\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"output_drop_prob\": 0.75,\n",
      "    \"percent_keep\": 1.0,\n",
      "    \"token_level_eval\": false,\n",
      "    \"train_steps\": 20000,\n",
      "    \"verbosity\": 1,\n",
      "    \"viterbi\": false,\n",
      "    \"window_size\": 7,\n",
      "    \"word_features\": false,\n",
      "    \"wordvecs\": \"./vectorfile/bio_nlp_vec/PubMed-shuffle-win-30.bin\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "MTL_instance = MTL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Load data calling the read_dataset method and pass the path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = MTL_instance.read_dataset(\"./data/CHEMDNER\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "After the data is loaded, pass them to the train method\n",
    "\n",
    "As for a demo, we only train for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./:setting embedding_lr_multiplier not defined\n",
      "./:incomplete weights, added 1 missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samtom/project/MTL-env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./:From /home/samtom/project/MTL-env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samtom/project/MTL-env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2385: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./:From /home/samtom/project/MTL-env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2385: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samtom/project/MTL-env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./:From /home/samtom/project/MTL-env/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 604216. Keeping: 604216.0\n",
      "Epoch 1/1\n",
      "604216/604216 [==============================] - 123s - loss: 0.1960 - acc: 0.9497   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./:Ep: 1 123s (start 2019-05-01 03:22:05, end 2019-05-01 03:24:08)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MTL_instance.train(read_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Pass the test data which is contained in the read_data object.\n",
    "\n",
    "Call the predict function and get the output file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file has been created at: ./prediction/chemdner_output.tsv\n"
     ]
    }
   ],
   "source": [
    "output_file = MTL_instance.predict(read_data)\n",
    "print(\"Output file has been created at: {}\".format(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(output_file, \"r\")\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply open and read in the output file\n",
    "\n",
    "We can see the sample of prediction as follow\n",
    "\n",
    "For each line, the first column is the word, the second is the groundtruth entity, and the third is the prediction entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beneficial O O\\n',\n",
       " 'substances O O\\n',\n",
       " 'e O O\\n',\n",
       " 'g O O\\n',\n",
       " 'docosahexaenoic B-FAMILY B-TRIVIAL\\n',\n",
       " 'acids I-FAMILY I-FAMILY\\n',\n",
       " 'but O O\\n',\n",
       " 'also O O\\n',\n",
       " 'harmful O O\\n',\n",
       " 'compounds O O\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[30:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Call the evaluate function and pass the output_file in it.\n",
    "\n",
    "From the output, the Precision, Recall and F1_score are printed\n",
    "\n",
    "At the last row, the average score of the whole model is printed.\n",
    "\n",
    "Since the demo only train for 1 epoch, the F1_score is not ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-FORMULA Precision:76.98% Recall:64.22% F1_score:70.02% \n",
      "I-FORMULA Precision:62.49% Recall:63.39% F1_score:62.94% \n",
      "B-TRIVIAL Precision:73.38% Recall:68.94% F1_score:71.09% \n",
      "I-FAMILY Precision:61.53% Recall:37.62% F1_score:46.69% \n",
      "B-SYSTEMATIC Precision:77.15% Recall:56.79% F1_score:65.43% \n",
      "O Precision:97.63% Recall:99.58% F1_score:98.59% \n",
      "I-TRIVIAL Precision:70.82% Recall:24.13% F1_score:35.99% \n",
      "B-FAMILY Precision:61.75% Recall:42.21% F1_score:50.15% \n",
      "B-ABBREVIATION Precision:69.45% Recall:35.50% F1_score:46.98% \n",
      "I-SYSTEMATIC Precision:71.53% Recall:75.75% F1_score:73.58% \n",
      "Average Score:\n",
      "Precision:72.27% Recall:56.81% F1_score:62.15% \n"
     ]
    }
   ],
   "source": [
    "score = MTL_instance.evaluate(output_file, None)\n",
    "print(\"Average Score:\")\n",
    "print(\"Precision:{:.2f}% Recall:{:.2f}% F1_score:{:.2f}% \".format(score[0]*100, score[1]*100, score[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
