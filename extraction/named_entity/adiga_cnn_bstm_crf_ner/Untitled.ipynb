{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_final import NeuralSequenceLabeler\n",
    "from utils import parseconfig\n",
    "from utils.conll2003_prepro import process_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = parseconfig.parseConfig()\n",
    "file_dict = {\"train\":os.path.join(config[\"raw_path\"], \"train1.txt\"),\"dev\":os.path.join(config[\"raw_path\"], \"valid1.txt\"),\"test\":os.path.join(config[\"raw_path\"], \"test1.txt\")}\n",
    "neuralSequenceLabeler =  NeuralSequenceLabeler(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate object of NeuralSequenceLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralSequenceLabeler =  NeuralSequenceLabeler(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data/raw/benchmark_dataset/raw/train1.txt\n",
      "split data/raw/benchmark_dataset/raw/test1.txt\n",
      "split data/raw/benchmark_dataset/raw/valid1.txt\n",
      "inside read_dataset\n",
      "train 219554\n",
      "dev 55044\n",
      "test 50350\n"
     ]
    }
   ],
   "source": [
    "dataset = neuralSequenceLabeler.read_dataset(file_dict,\"ontonotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inititalise metadata & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word embedding shape: [None, None, 300]\n",
      "chars representation shape: [None, None, 200]\n",
      "word and chars concatenation shape: [None, None, 500]\n",
      "rnn output shape: [None, None, 600]\n",
      "logits shape: [None, None, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryaadiga/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params number: 6039690\n"
     ]
    }
   ],
   "source": [
    "train_set,dev_set,test_set,vocab = process_data(dataset,config)\n",
    "neuralSequenceLabeler.initialize_metadata(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {\"train\": train_set, \"dev\":dev_set,\"test\":test_set }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load model....\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    neuralSequenceLabeler.load_model()\n",
    "except:\n",
    "    print(\"Error loading the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14987\n",
      "3466\n",
      "3684\n"
     ]
    }
   ],
   "source": [
    "dataset = neuralSequenceLabeler.read_dataset_helper(file_dict,\"ontonotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch 1/2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 605s - Global Step: 750 - Train Loss: 3.0879   \n",
      "\n",
      "\n",
      "in predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev dataset -- pre: 76.35, rec: 79.21, FB1: 77.75\n",
      " -- new BEST score on test dataset: 77.75\n",
      "Epoch 2/2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 554s - Global Step: 1500 - Train Loss: 0.7879   \n",
      "\n",
      "\n",
      "in predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev dataset -- pre: 81.73, rec: 83.85, FB1: 82.78\n",
      " -- new BEST score on test dataset: 82.78\n"
     ]
    }
   ],
   "source": [
    "neuralSequenceLabeler.train(dataset[\"train_set\"],dataset[\"dev_data\"],dataset[\"dev_set\"],dataset[\"test_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
