{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeeweonlee/anaconda3/envs/nfetc/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "from entity_tpying_subclass import NFETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"./data/corpus/Wiki/all.txt\" # raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating my model...\n"
     ]
    }
   ],
   "source": [
    "print(\"> Creating my model...\")\n",
    "myModel = NFETC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = input_file_path\n",
    "folder_path = \"/\".join(file_path.split(\"/\")[:-1])\n",
    "data_name = \"wiki\"\n",
    "model_name = \"best_nfetc_wiki\"\n",
    "# ratio = (0.90, 0.05, 0.05)\n",
    "ratio = (0.7, 0.15, 0.15)\n",
    "\n",
    "# Mandatory options for my Model\n",
    "options = {}\n",
    "options[\"data_name\"] = data_name\n",
    "options[\"ratio\"] = ratio\n",
    "options[\"model_name\"] = model_name\n",
    "# model_names = {\n",
    "#\t \"nfetc\": param_space_nfetc,\n",
    "#\t \"best_nfetc_wiki\": param_space_best_nfetc_wiki,\n",
    "#\t \"best_nfetc_wiki_hier\": param_space_best_nfetc_wiki_hier,\n",
    "#\t \"best_nfetc_ontonotes\": param_space_best_nfetc_ontonotes,\n",
    "#\t \"best_nfetc_ontonotes_hier\": param_space_best_nfetc_ontonotes_hier,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reading dataset ...\n",
      ">> Split all.txt to train, dev, test data with ratio, (0.7, 0.15, 0.15) under ./data/corpus/Wiki\n",
      ">> Finished! \n",
      ">> Initiate Task\n",
      ">>> Loading data...\n",
      "5622 unique tokens have been found!\n",
      ">>> Preprocessing data...\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/nfetc.py:113: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/nfetc.py:120: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/nfetc.py:140: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"> Reading dataset ...\")\n",
    "extension = file_path.split(\".\")[-1]\n",
    "if extension == \"txt\":\n",
    "\tmyModel.split_data_txt(file_path, folder_path, ratio)\n",
    "elif extension == \"tsv\":\n",
    "\tmyModel.split_data_tsv(file_path, folder_path, ratio)\n",
    "myModel.preprocess_helper(data_name, extension)\n",
    "train_data, test_data = myModel.read_dataset(file_path, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Training ...\n",
      ">> In train, train_data size: ( 850 )\n",
      ">> There is Enough data to train.\n",
      "2019-04-23T21:15:45.431621: step 1, loss 4.79814 pacc 0.0488281 eacc 0.03125\n",
      "2019-04-23T21:15:46.924794: step 2, loss 4.71013 pacc 0.0384615 eacc 0.0236686\n",
      "2019-04-23T21:15:48.820952: step 3, loss 4.64705 pacc 0.0488281 eacc 0.03125\n",
      "2019-04-23T21:15:49.892395: step 4, loss 4.69767 pacc 0.0473373 eacc 0.0266272\n",
      "2019-04-23T21:15:51.418989: step 5, loss 4.52169 pacc 0.0703125 eacc 0.0449219\n",
      "2019-04-23T21:15:52.497863: step 6, loss 4.59961 pacc 0.0473373 eacc 0.0414201\n",
      "2019-04-23T21:15:54.045925: step 7, loss 4.36278 pacc 0.0761719 eacc 0.0390625\n",
      "2019-04-23T21:15:55.132174: step 8, loss 4.3636 pacc 0.0798817 eacc 0.0532544\n",
      "2019-04-23T21:15:56.911333: step 9, loss 4.36042 pacc 0.0683594 eacc 0.0449219\n",
      "2019-04-23T21:15:58.102018: step 10, loss 4.28651 pacc 0.0710059 eacc 0.0384615\n",
      "2019-04-23T21:16:00.091147: step 11, loss 4.25169 pacc 0.0800781 eacc 0.0585938\n",
      "2019-04-23T21:16:01.166248: step 12, loss 4.26764 pacc 0.0798817 eacc 0.0443787\n",
      "2019-04-23T21:16:02.729549: step 13, loss 4.08139 pacc 0.0957031 eacc 0.0507812\n",
      "2019-04-23T21:16:03.827830: step 14, loss 4.0479 pacc 0.121302 eacc 0.0680473\n",
      "2019-04-23T21:16:05.349749: step 15, loss 4.00074 pacc 0.107422 eacc 0.0683594\n",
      "2019-04-23T21:16:06.440716: step 16, loss 4.08937 pacc 0.121302 eacc 0.0680473\n",
      "2019-04-23T21:16:07.961431: step 17, loss 3.90457 pacc 0.132812 eacc 0.0878906\n",
      "2019-04-23T21:16:09.038974: step 18, loss 3.9033 pacc 0.183432 eacc 0.118343\n",
      "2019-04-23T21:16:10.554114: step 19, loss 3.78288 pacc 0.160156 eacc 0.111328\n",
      "2019-04-23T21:16:11.639513: step 20, loss 3.87432 pacc 0.171598 eacc 0.115385\n",
      "2019-04-23T21:16:13.160660: step 21, loss 3.70135 pacc 0.189453 eacc 0.126953\n",
      "2019-04-23T21:16:14.258354: step 22, loss 3.67776 pacc 0.201183 eacc 0.115385\n",
      "2019-04-23T21:16:15.786593: step 23, loss 3.70068 pacc 0.21875 eacc 0.140625\n",
      "2019-04-23T21:16:16.855011: step 24, loss 3.64608 pacc 0.186391 eacc 0.100592\n",
      "2019-04-23T21:16:18.376765: step 25, loss 3.53739 pacc 0.220703 eacc 0.140625\n",
      "2019-04-23T21:16:19.465682: step 26, loss 3.54066 pacc 0.239645 eacc 0.136095\n",
      "2019-04-23T21:16:20.972774: step 27, loss 3.45066 pacc 0.242188 eacc 0.152344\n",
      "2019-04-23T21:16:22.062390: step 28, loss 3.45583 pacc 0.251479 eacc 0.159763\n",
      "2019-04-23T21:16:23.589868: step 29, loss 3.42501 pacc 0.283203 eacc 0.183594\n",
      "2019-04-23T21:16:24.690659: step 30, loss 3.35674 pacc 0.286982 eacc 0.171598\n",
      "2019-04-23T21:16:26.208577: step 31, loss 3.33224 pacc 0.269531 eacc 0.164062\n",
      "2019-04-23T21:16:27.274516: step 32, loss 3.156 pacc 0.316568 eacc 0.192308\n",
      "2019-04-23T21:16:29.330213: step 33, loss 3.1986 pacc 0.326172 eacc 0.205078\n",
      "2019-04-23T21:16:30.494421: step 34, loss 3.12023 pacc 0.372781 eacc 0.233728\n",
      "2019-04-23T21:16:32.385213: step 35, loss 3.12957 pacc 0.339844 eacc 0.201172\n",
      "2019-04-23T21:16:33.539261: step 36, loss 3.0257 pacc 0.384615 eacc 0.224852\n",
      "2019-04-23T21:16:35.062631: step 37, loss 3.06446 pacc 0.353516 eacc 0.234375\n",
      "2019-04-23T21:16:36.141139: step 38, loss 3.00802 pacc 0.363905 eacc 0.210059\n",
      "2019-04-23T21:16:37.858116: step 39, loss 2.97665 pacc 0.382812 eacc 0.246094\n",
      "2019-04-23T21:16:38.934893: step 40, loss 2.83181 pacc 0.440828 eacc 0.278107\n",
      "Saved model to /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/checkpoint/best_nfetc_wiki\n",
      ">> Training is Done ! \n"
     ]
    }
   ],
   "source": [
    "print(\"> Training ...\") \n",
    "myModel.train(train_data, options) # saved trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Predicting ...\n",
      ">> In predict, test_data size: ( 150 )\n",
      ">> There is Enough data to predict.\n",
      ">>> Restored prev-trained model...\n",
      "WARNING:tensorflow:From /Users/jeeweonlee/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/checkpoint/best_nfetc_wiki\n",
      ">>> Restored prev-trained model...\n",
      "INFO:tensorflow:Restoring parameters from /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/checkpoint/best_nfetc_wiki\n",
      ">>> Restored prev-trained model...\n",
      "INFO:tensorflow:Restoring parameters from /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/checkpoint/best_nfetc_wiki\n",
      ">>> Restored prev-trained model...\n",
      "INFO:tensorflow:Restoring parameters from /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/checkpoint/best_nfetc_wiki\n",
      ">>> Restored prev-trained model...\n",
      "INFO:tensorflow:Restoring parameters from /Users/jeeweonlee/_G1/tmp548/_GitCode/NFETC/checkpoint/best_nfetc_wiki\n",
      ">> prediction_data size: ( 150 )\n",
      ">> Prediction is Done ! \n"
     ]
    }
   ],
   "source": [
    "print(\"> Predicting ...\")\n",
    "# predict_data = None\n",
    "predict_data = myModel.predict(test_data, None, options) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Evaluating ...\n",
      ">> In evaluate, test_data size: ( 150 )\n",
      ">> There is Enough data to evaluate.\n",
      "Strict Accuracy: 0.08666666666666667\n",
      "Loose Macro:\n",
      "Precision 0.29333333333333333 Recall 0.2871269841269841 F1 0.2901969792264851\n",
      "Loose Micro:\n",
      "Precision 0.3 Recall 0.25225225225225223 F1 0.2740619902120718\n",
      ">> Evaluation is Done ! \n"
     ]
    }
   ],
   "source": [
    "print(\"> Evaluating ...\")\n",
    "acc, macro, micro = myModel.evaluate(test_data, predict_data, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/best_nfetc_wiki.tsv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"./output/\" + model_name + \".tsv\"\n",
    "print(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
