{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os import sys, path \n",
    "#Make Sure Parent File is stored properly for demo!\n",
    "from Imputation import Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class GAIN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization for mini batch size, missing rate, hint rate, alpha and train rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(Imputation):\n",
    "    def __init__(self, mb_size, p_miss, p_hint, alpha, train_rate):\n",
    "        self.mb_size= mb_size\n",
    "        self.p_miss = p_miss\n",
    "        self.p_hint = p_hint\n",
    "        self.alpha = alpha\n",
    "        self.train_rate = train_rate\n",
    "        self.H_Dim1 = None\n",
    "        self.H_Dim2 = None\n",
    "        print('Init Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for normalize, missingness introduction, train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def normalize(self, data, dimension):\n",
    "            Min_Val = np.zeros(dimension)\n",
    "            Max_Val = np.zeros(dimension)\n",
    "            for i in range(dimension):\n",
    "                Min_Val[i] = np.min(data[:,i])\n",
    "                data[:,i] = data[:,i] - np.min(data[:,i])\n",
    "                Max_Val[i] = np.max(data[:,i])\n",
    "                data[:,i] = data[:,i] / (np.max(data[:,i]) + 1e-6)  \n",
    "            print('Norm Done')              \n",
    "            return data   \n",
    "    \n",
    "    def introduce_missingness(self, Dim, No, Data):\n",
    "            p_miss_vec = self.p_miss * np.ones((Dim,1))\n",
    "            Missing = np.zeros((No, Dim))\n",
    "            for i in range(Dim):\n",
    "                A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "                B = A > p_miss_vec[i]\n",
    "                Missing[:,i] = 1.*B\n",
    "            print('Missing Done')\n",
    "            return Missing\n",
    "    \n",
    "    def train_test_split(self, No, Data, Missing):\n",
    "        idx = np.random.permutation(No)\n",
    "        Train_No = int(No * self.train_rate)\n",
    "        Test_No = No - Train_No\n",
    "        trainX = Data[idx[:Train_No],:]\n",
    "        testX = Data[idx[Train_No:],:]\n",
    "        trainM = Missing[idx[:Train_No],:]\n",
    "        testM = Missing[idx[Train_No:],:]\n",
    "        print('Train/Test Done')\n",
    "        return trainX, testX, trainM, testM, Train_No, Test_No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing gain architecture, generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def gain_architecture(self, Dim):\n",
    "            X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            M = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            H = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            New_X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
    "            D_W1 = tf.Variable(self.xavier_init([Dim*2, self.H_Dim1]))     # Data + Hint as inputs\n",
    "            D_b1 = tf.Variable(tf.zeros(shape = [ self.H_Dim1]))\n",
    "            D_W2 = tf.Variable(self.xavier_init([self.H_Dim1, self.H_Dim2]))\n",
    "            D_b2 = tf.Variable(tf.zeros(shape = [self.H_Dim2]))\n",
    "            D_W3 = tf.Variable(self.xavier_init([self.H_Dim2, Dim]))\n",
    "            D_b3 = tf.Variable(tf.zeros(shape = [Dim]))       # Output is multi-variate\n",
    "            theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "            G_W1 = tf.Variable(self.xavier_init([Dim*2, self.H_Dim1]))     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "            G_b1 = tf.Variable(tf.zeros(shape = [self.H_Dim1]))\n",
    "            G_W2 = tf.Variable(self.xavier_init([self.H_Dim1, self.H_Dim2]))\n",
    "            G_b2 = tf.Variable(tf.zeros(shape = [self.H_Dim2]))\n",
    "            G_W3 = tf.Variable(self.xavier_init([self.H_Dim2, Dim]))\n",
    "            G_b3 = tf.Variable(tf.zeros(shape = [Dim]))\n",
    "            theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "            print('Gain Arch Done')\n",
    "            return theta_D, theta_G, X, M, H, New_X\n",
    "    @staticmethod\n",
    "    def generator(new_x, m, G_W1, G_W2, G_W3, G_b1, G_b2, G_b3):\n",
    "        inputs = tf.concat(axis = 1, values = [new_x,m])  # Mask + Data Concatenate\n",
    "        G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
    "        G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)   \n",
    "        G_prob = tf.nn.sigmoid(tf.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "        print('Gen Samp Done')\n",
    "        return G_prob\n",
    "            \n",
    "    @staticmethod\n",
    "    def discriminator(new_x, h, D_W1, D_W2, D_W3, D_b1, D_b2, D_b3):\n",
    "        inputs = tf.concat(axis = 1, values = [new_x,h])  # Hint + Data Concatenate\n",
    "        D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)  \n",
    "        D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n",
    "        D_logit = tf.matmul(D_h2, D_W3) + D_b3\n",
    "        D_prob = tf.nn.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "        print('Disc Sample Done')\n",
    "        return D_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preprocessing input data : normalize, load, get dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def preprocess(self, inputData):\n",
    "            Data = np.loadtxt(inputData, delimiter=\",\",skiprows=1)\n",
    "            #Data = np.loadtxt(inputData, delimiter=\",\")\n",
    "            No = len(Data)\n",
    "            Dim = len(Data[0,:])\n",
    "            self.H_Dim1 = Dim\n",
    "            self.H_Dim2 = Dim\n",
    "            normalized_data = self.normalize(Data, Dim)\n",
    "            print('Preprocess Done')\n",
    "            return normalized_data, No, Dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static methods: xavier initialization, sample generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    @staticmethod\n",
    "    def xavier_init(size):\n",
    "        in_dim = size[0]\n",
    "        xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "        return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "    @staticmethod\n",
    "    def sample_M(m, n, p):\n",
    "        A = np.random.uniform(0., 1., size = [m, n])\n",
    "        B = A > p\n",
    "        C = 1.*B\n",
    "        return C    \n",
    "    @staticmethod\n",
    "    def sample_Z(m, n):\n",
    "        return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "    @staticmethod\n",
    "    def sample_idx(m, n):\n",
    "         A = np.random.permutation(m)\n",
    "         idx = A[:n]\n",
    "         return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):    \n",
    "    def train(self, normalized_data, No, Dim):\n",
    "        missing_matrix  = self.introduce_missingness(Dim, No, normalized_data)\n",
    "        trainX, testX, trainM, testM, Train_No, Test_No= self.train_test_split(No, normalized_data, missing_matrix)\n",
    "        theta_D, theta_G, X, M, H, New_X = self.gain_architecture(Dim)\n",
    "        G_sample = self.generator(New_X, M, theta_G[0],theta_G[1], theta_G[2], theta_G[3], theta_G[4], theta_G[5])\n",
    "        Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "        D_prob = self.discriminator(Hat_New_X, H, theta_D[0], theta_D[1], theta_D[2], theta_D[3],theta_D[4],theta_D[5])\n",
    "        D_loss1 = -tf.reduce_mean(M * tf.log(D_prob + 1e-8) + (1-M) * tf.log(1. - D_prob + 1e-8)) \n",
    "        G_loss1 = -tf.reduce_mean((1-M) * tf.log(D_prob + 1e-8))\n",
    "        MSE_train_loss = tf.reduce_mean((M * New_X - M * G_sample)**2) / tf.reduce_mean(M)\n",
    "        D_loss = D_loss1\n",
    "        G_loss = G_loss1 + gain_obj.alpha * MSE_train_loss\n",
    "        MSE_test_loss = tf.reduce_mean(((1-M) * X - (1-M)*G_sample)**2) / tf.reduce_mean(1-M)\n",
    "        D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "        G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for it in tqdm(range(5000)):    \n",
    "            mb_idx = gain_obj.sample_idx(Train_No, gain_obj.mb_size)\n",
    "            X_mb = trainX[mb_idx,:]      \n",
    "            Z_mb = gain_obj.sample_Z(gain_obj.mb_size, Dim) \n",
    "            M_mb = trainM[mb_idx,:]  \n",
    "            H_mb1 = gain_obj.sample_M(gain_obj.mb_size, Dim, 1-gain_obj.p_hint)\n",
    "            H_mb = M_mb * H_mb1    \n",
    "            New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce    \n",
    "            _, D_loss_curr = sess.run([D_solver, D_loss1], feed_dict = {M: M_mb, New_X: New_X_mb, H: H_mb})\n",
    "            _, G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = sess.run([G_solver, G_loss1, MSE_train_loss, MSE_test_loss],\n",
    "                                                                           feed_dict = {X: X_mb, M: M_mb, New_X: New_X_mb, H: H_mb})\n",
    "            if it % 100 == 0:\n",
    "                print('Iter: {}'.format(it))\n",
    "                print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr)))\n",
    "                print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr)))\n",
    "                print()\n",
    "        return Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test functions, impute, evaluate. [Evaluate results are provided in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAIN(GAIN):\n",
    "    def test(self, Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X):\n",
    "        Z_mb = gain_obj.sample_Z(Test_No, Dim) \n",
    "        M_mb = testM\n",
    "        X_mb = testX\n",
    "        New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "        MSE_final, Sample = sess.run([MSE_test_loss, G_sample], feed_dict = {X: testX, M: testM, New_X: New_X_mb})\n",
    "        print('Final Test RMSE: ' + str(np.sqrt(MSE_final)))\n",
    "        \n",
    "    def impute(self, trained_model, input):\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, trained_model, input):\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function to access GAIN, initial params, and with dataset in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Done\n",
      "Norm Done\n",
      "Preprocess Done\n",
      "Missing Done\n",
      "Train/Test Done\n",
      "Gain Arch Done\n",
      "Gen Samp Done\n",
      "Disc Sample Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/5000 [00:00<14:29,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Train_loss: 0.3289\n",
      "Test_loss: 0.3305\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 141/5000 [00:00<03:37, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Train_loss: 0.1767\n",
      "Test_loss: 0.1831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 239/5000 [00:01<01:06, 71.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "Train_loss: 0.1494\n",
      "Test_loss: 0.1553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 355/5000 [00:01<00:27, 167.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 300\n",
      "Train_loss: 0.1392\n",
      "Test_loss: 0.1418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 439/5000 [00:01<00:21, 215.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 400\n",
      "Train_loss: 0.1285\n",
      "Test_loss: 0.1486\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 557/5000 [00:02<00:16, 268.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "Train_loss: 0.1164\n",
      "Test_loss: 0.1374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 647/5000 [00:02<00:15, 288.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 600\n",
      "Train_loss: 0.1162\n",
      "Test_loss: 0.1521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 738/5000 [00:02<00:14, 294.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 700\n",
      "Train_loss: 0.1018\n",
      "Test_loss: 0.1297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 859/5000 [00:03<00:13, 297.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 800\n",
      "Train_loss: 0.09752\n",
      "Test_loss: 0.1269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 919/5000 [00:03<00:14, 279.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 900\n",
      "Train_loss: 0.09116\n",
      "Test_loss: 0.1248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1034/5000 [00:04<00:14, 269.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1000\n",
      "Train_loss: 0.09196\n",
      "Test_loss: 0.1396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1146/5000 [00:04<00:15, 255.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1100\n",
      "Train_loss: 0.08556\n",
      "Test_loss: 0.1293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1261/5000 [00:04<00:13, 277.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1200\n",
      "Train_loss: 0.07883\n",
      "Test_loss: 0.1408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1351/5000 [00:05<00:12, 289.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1300\n",
      "Train_loss: 0.07718\n",
      "Test_loss: 0.1297\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1439/5000 [00:05<00:13, 260.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1400\n",
      "Train_loss: 0.07889\n",
      "Test_loss: 0.1374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1553/5000 [00:05<00:12, 271.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1500\n",
      "Train_loss: 0.07253\n",
      "Test_loss: 0.1305\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1635/5000 [00:06<00:13, 245.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1600\n",
      "Train_loss: 0.07534\n",
      "Test_loss: 0.129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1746/5000 [00:06<00:12, 265.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1700\n",
      "Train_loss: 0.07019\n",
      "Test_loss: 0.1155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1830/5000 [00:07<00:11, 272.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1800\n",
      "Train_loss: 0.07149\n",
      "Test_loss: 0.1309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1945/5000 [00:07<00:10, 281.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1900\n",
      "Train_loss: 0.06848\n",
      "Test_loss: 0.128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2032/5000 [00:07<00:10, 282.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2000\n",
      "Train_loss: 0.07152\n",
      "Test_loss: 0.1281\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2149/5000 [00:08<00:10, 283.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2100\n",
      "Train_loss: 0.06919\n",
      "Test_loss: 0.1288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2234/5000 [00:08<00:10, 268.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2200\n",
      "Train_loss: 0.06553\n",
      "Test_loss: 0.1427\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2342/5000 [00:08<00:10, 263.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2300\n",
      "Train_loss: 0.07171\n",
      "Test_loss: 0.1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2455/5000 [00:09<00:09, 274.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2400\n",
      "Train_loss: 0.06705\n",
      "Test_loss: 0.1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2538/5000 [00:09<00:09, 261.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2500\n",
      "Train_loss: 0.06336\n",
      "Test_loss: 0.1271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2642/5000 [00:10<00:09, 247.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2600\n",
      "Train_loss: 0.06793\n",
      "Test_loss: 0.1283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2755/5000 [00:10<00:08, 270.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2700\n",
      "Train_loss: 0.06227\n",
      "Test_loss: 0.1233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2843/5000 [00:10<00:07, 279.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2800\n",
      "Train_loss: 0.06099\n",
      "Test_loss: 0.1226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2961/5000 [00:11<00:07, 286.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2900\n",
      "Train_loss: 0.06427\n",
      "Test_loss: 0.1246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3043/5000 [00:11<00:08, 241.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3000\n",
      "Train_loss: 0.06245\n",
      "Test_loss: 0.1178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3154/5000 [00:11<00:06, 264.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3100\n",
      "Train_loss: 0.06055\n",
      "Test_loss: 0.1191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 3233/5000 [00:12<00:07, 250.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3200\n",
      "Train_loss: 0.05801\n",
      "Test_loss: 0.1218\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3343/5000 [00:12<00:06, 259.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3300\n",
      "Train_loss: 0.06217\n",
      "Test_loss: 0.1327\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3446/5000 [00:13<00:06, 244.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3400\n",
      "Train_loss: 0.05892\n",
      "Test_loss: 0.1064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3533/5000 [00:13<00:05, 269.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3500\n",
      "Train_loss: 0.06042\n",
      "Test_loss: 0.1266\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3641/5000 [00:13<00:05, 233.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3600\n",
      "Train_loss: 0.06157\n",
      "Test_loss: 0.1269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 3736/5000 [00:14<00:05, 226.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3700\n",
      "Train_loss: 0.05782\n",
      "Test_loss: 0.1312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3850/5000 [00:14<00:04, 265.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3800\n",
      "Train_loss: 0.05971\n",
      "Test_loss: 0.1385\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 3930/5000 [00:15<00:04, 250.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3900\n",
      "Train_loss: 0.05591\n",
      "Test_loss: 0.1332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4046/5000 [00:15<00:03, 278.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4000\n",
      "Train_loss: 0.0544\n",
      "Test_loss: 0.1183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4139/5000 [00:15<00:02, 297.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4100\n",
      "Train_loss: 0.05348\n",
      "Test_loss: 0.1193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 4232/5000 [00:16<00:02, 300.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4200\n",
      "Train_loss: 0.05797\n",
      "Test_loss: 0.1273\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4356/5000 [00:16<00:02, 301.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4300\n",
      "Train_loss: 0.05584\n",
      "Test_loss: 0.1261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4448/5000 [00:16<00:01, 300.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4400\n",
      "Train_loss: 0.05453\n",
      "Test_loss: 0.1303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4542/5000 [00:17<00:01, 305.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4500\n",
      "Train_loss: 0.05198\n",
      "Test_loss: 0.1267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4635/5000 [00:17<00:01, 302.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4600\n",
      "Train_loss: 0.05181\n",
      "Test_loss: 0.1168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 4759/5000 [00:17<00:00, 304.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4700\n",
      "Train_loss: 0.04897\n",
      "Test_loss: 0.1212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4852/5000 [00:18<00:00, 301.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4800\n",
      "Train_loss: 0.05407\n",
      "Test_loss: 0.1293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4945/5000 [00:18<00:00, 301.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4900\n",
      "Train_loss: 0.05227\n",
      "Test_loss: 0.1235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:18<00:00, 267.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test RMSE: 0.12908025\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    gain_obj = GAIN(128, 0.2, 0.9, 10, 0.8)\n",
    "    normalized_data, No, Dim= gain_obj.preprocess('Letter.csv')\n",
    "    Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X = gain_obj.train(normalized_data, No, Dim)\n",
    "    gain_obj.test(Test_No, testM, testX, MSE_test_loss, G_sample, sess, X, M, New_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
